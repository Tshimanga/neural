<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Numeric.Neural.Layer</title><link href="ocean.css" rel="stylesheet" type="text/css" title="Ocean" /><script src="haddock-util.js" type="text/javascript"></script><script type="text/javascript">//<![CDATA[
window.onload = function () {pageLoad();setSynopsis("mini_Numeric-Neural-Layer.html");};
//]]>
</script></head><body><div id="package-header"><ul class="links" id="page-menu"><li><a href="src/Numeric-Neural-Layer.html">Source</a></li><li><a href="index.html">Contents</a></li><li><a href="doc-index.html">Index</a></li></ul><p class="caption">neural-0.1.0.1: Neural Networks in native Haskell</p></div><div id="content"><div id="module-header"><table class="info"><tr><th>Copyright</th><td>(c) Lars Br&#252;njes, 2016</td></tr><tr><th>License</th><td>MIT</td></tr><tr><th>Maintainer</th><td>brunjlar@gmail.com</td></tr><tr><th>Stability</th><td>experimental</td></tr><tr><th>Portability</th><td>portable</td></tr><tr><th>Safe Haskell</th><td>None</td></tr><tr><th>Language</th><td>Haskell2010</td></tr><tr><th>Extensions</th><td><ul class="extension-list"><li>ScopedTypeVariables</li><li>DataKinds</li><li>TypeOperators</li><li>ExplicitNamespaces</li><li>ExplicitForAll</li></ul></td></tr></table><p class="caption">Numeric.Neural.Layer</p></div><div id="description"><p class="caption">Description</p><div class="doc"><p>This modules defines special &quot;layer&quot; components and convenience functions for the creation of such layers.</p></div></div><div id="synopsis"><p id="control.syn" class="caption expander" onclick="toggleSection('syn')">Synopsis</p><ul id="section.syn" class="hide" onclick="toggleSection('syn')"><li class="src short"><span class="keyword">type</span> <a href="#t:Layer">Layer</a> i o = <a href="Numeric-Neural-Model.html#t:Component">Component</a> (<a href="Data-Utils-Vector.html#t:Vector">Vector</a> i <a href="Data-Utils-Analytic.html#t:Analytic">Analytic</a>) (<a href="Data-Utils-Vector.html#t:Vector">Vector</a> o <a href="Data-Utils-Analytic.html#t:Analytic">Analytic</a>)</li><li class="src short"><a href="#v:linearLayer">linearLayer</a> :: <span class="keyword">forall</span> i o. (<a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> i, <a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> o) =&gt; <a href="Numeric-Neural-Layer.html#t:Layer">Layer</a> i o</li><li class="src short"><a href="#v:layer">layer</a> :: (<a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> i, <a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> o) =&gt; (<a href="Data-Utils-Analytic.html#t:Analytic">Analytic</a> -&gt; <a href="Data-Utils-Analytic.html#t:Analytic">Analytic</a>) -&gt; <a href="Numeric-Neural-Layer.html#t:Layer">Layer</a> i o</li><li class="src short"><a href="#v:tanhLayer">tanhLayer</a> :: (<a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> i, <a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> o) =&gt; <a href="Numeric-Neural-Layer.html#t:Layer">Layer</a> i o</li><li class="src short"><a href="#v:logisticLayer">logisticLayer</a> :: (<a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> i, <a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> o) =&gt; <a href="Numeric-Neural-Layer.html#t:Layer">Layer</a> i o</li><li class="src short"><a href="#v:softmax">softmax</a> :: (<a href="../base-4.8.2.0/Prelude.html#t:Floating">Floating</a> a, <a href="../base-4.8.2.0/Data-Functor.html#t:Functor">Functor</a> f, <a href="../base-4.8.2.0/Data-Foldable.html#t:Foldable">Foldable</a> f) =&gt; f a -&gt; f a</li></ul></div><div id="interface"><h1>Documentation</h1><div class="top"><p class="src"><span class="keyword">type</span> <a name="t:Layer" class="def">Layer</a> i o = <a href="Numeric-Neural-Model.html#t:Component">Component</a> (<a href="Data-Utils-Vector.html#t:Vector">Vector</a> i <a href="Data-Utils-Analytic.html#t:Analytic">Analytic</a>) (<a href="Data-Utils-Vector.html#t:Vector">Vector</a> o <a href="Data-Utils-Analytic.html#t:Analytic">Analytic</a>) <a href="src/Numeric-Neural-Layer.html#Layer" class="link">Source</a></p><div class="doc"><p>A <code><code><a href="Numeric-Neural-Layer.html#t:Layer">Layer</a></code> i o</code> is a component that maps a vector of length <code>i</code> to a vector of length <code>j</code>.</p></div></div><div class="top"><p class="src"><a name="v:linearLayer" class="def">linearLayer</a> :: <span class="keyword">forall</span> i o. (<a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> i, <a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> o) =&gt; <a href="Numeric-Neural-Layer.html#t:Layer">Layer</a> i o <a href="src/Numeric-Neural-Layer.html#linearLayer" class="link">Source</a></p><div class="doc"><p>Creates a <em>linear</em> <code><a href="Numeric-Neural-Layer.html#t:Layer">Layer</a></code>, i.e. a layer that multiplies the input with a weight matrix and adds a bias to get the output.</p></div></div><div class="top"><p class="src"><a name="v:layer" class="def">layer</a> :: (<a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> i, <a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> o) =&gt; (<a href="Data-Utils-Analytic.html#t:Analytic">Analytic</a> -&gt; <a href="Data-Utils-Analytic.html#t:Analytic">Analytic</a>) -&gt; <a href="Numeric-Neural-Layer.html#t:Layer">Layer</a> i o <a href="src/Numeric-Neural-Layer.html#layer" class="link">Source</a></p><div class="doc"><p>Creates a <code><a href="Numeric-Neural-Layer.html#t:Layer">Layer</a></code> as a combination of a linear layer and a non-linear activation function.</p></div></div><div class="top"><p class="src"><a name="v:tanhLayer" class="def">tanhLayer</a> :: (<a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> i, <a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> o) =&gt; <a href="Numeric-Neural-Layer.html#t:Layer">Layer</a> i o <a href="src/Numeric-Neural-Layer.html#tanhLayer" class="link">Source</a></p><div class="doc"><p>This is simply <code><a href="Numeric-Neural-Layer.html#v:layer">layer</a></code>, specialized to <code><a href="../base-4.8.2.0/Prelude.html#v:tanh">tanh</a></code>-activation. Output values are all in the interval [0,1].</p></div></div><div class="top"><p class="src"><a name="v:logisticLayer" class="def">logisticLayer</a> :: (<a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> i, <a href="Data-Utils-Vector.html#t:KnownNat">KnownNat</a> o) =&gt; <a href="Numeric-Neural-Layer.html#t:Layer">Layer</a> i o <a href="src/Numeric-Neural-Layer.html#logisticLayer" class="link">Source</a></p><div class="doc"><p>This is simply <code><a href="Numeric-Neural-Layer.html#v:layer">layer</a></code>, specialized to the logistic function as activation. Output values are all in the interval [-1,1].</p></div></div><div class="top"><p class="src"><a name="v:softmax" class="def">softmax</a> :: (<a href="../base-4.8.2.0/Prelude.html#t:Floating">Floating</a> a, <a href="../base-4.8.2.0/Data-Functor.html#t:Functor">Functor</a> f, <a href="../base-4.8.2.0/Data-Foldable.html#t:Foldable">Foldable</a> f) =&gt; f a -&gt; f a <a href="src/Numeric-Neural-Layer.html#softmax" class="link">Source</a></p><div class="doc"><p>The <code><a href="Numeric-Neural-Layer.html#v:softmax">softmax</a></code> function normalizes a vector, so that all entries are in [0,1] with sum 1. 
   This means the output entries can be interpreted as probabilities.</p></div></div></div></div><div id="footer"><p>Produced by <a href="http://www.haskell.org/haddock/">Haddock</a> version 2.16.1</p></div></body></html>